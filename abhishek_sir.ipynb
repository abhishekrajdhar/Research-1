{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7681c8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import timm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d1e7f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bdbc46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class HCDataset(Dataset):\n",
    "    def __init__(self, root, csv_path, transform=None):\n",
    "        self.root = root\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.transform = transform\n",
    "\n",
    "        self.images = sorted([f for f in os.listdir(root) if f.endswith(\"_HC.png\")])\n",
    "        self.spacing = dict(zip(self.df[\"filename\"], self.df[\"pixel size(mm)\"]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.images[idx]\n",
    "\n",
    "        img = cv2.imread(os.path.join(self.root, fname), 0).astype(np.float32) / 255.0\n",
    "        img = np.stack([img]*3, axis=-1)\n",
    "\n",
    "        mask = cv2.imread(\n",
    "            os.path.join(self.root, fname.replace(\".png\", \"_Annotation.png\")), 0\n",
    "        )\n",
    "        mask = (mask > 0).astype(np.float32)\n",
    "\n",
    "        if self.transform:\n",
    "            aug = self.transform(image=img, mask=mask)\n",
    "            img, mask = aug[\"image\"], aug[\"mask\"]\n",
    "\n",
    "        return img, mask, self.spacing[fname], fname\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb25d0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfms = A.Compose([\n",
    "    A.Resize(224,224),\n",
    "    A.Rotate(limit=20, p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5)),\n",
    "    ToTensorV2()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2c277b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinSeg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = timm.create_model(\n",
    "            \"swin_tiny_patch4_window7_224\",\n",
    "            pretrained=True,\n",
    "            features_only=True\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(768,256,2,2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256,64,2,2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.head = nn.Conv2d(64,1,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        f = self.encoder(x)[-1]          # (B, H', W', C)\n",
    "        f = f.permute(0,3,1,2)           # (B, C, H', W')\n",
    "\n",
    "        d = self.decoder(f)              # still low-res\n",
    "        out = self.head(d)\n",
    "\n",
    "        # ðŸ”¥ CRITICAL FIX: upsample to input size\n",
    "        out = torch.nn.functional.interpolate(\n",
    "            out,\n",
    "            size=x.shape[2:],            # (H, W) = 224x224\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False\n",
    "        )\n",
    "\n",
    "        return torch.sigmoid(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce5b6e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_score_torch(pred, target, eps=1e-6):\n",
    "    pred = (pred > 0.5).float()\n",
    "    target = target.float()\n",
    "\n",
    "    inter = (pred * target).sum(dim=(1,2,3))\n",
    "    union = pred.sum(dim=(1,2,3)) + target.sum(dim=(1,2,3))\n",
    "\n",
    "    return ((2 * inter + eps) / (union + eps)).mean().item()\n",
    "\n",
    "\n",
    "def iou_score_torch(pred, target, eps=1e-6):\n",
    "    pred = (pred > 0.5).float()\n",
    "    target = target.float()\n",
    "\n",
    "    inter = (pred * target).sum(dim=(1,2,3))\n",
    "    union = pred.sum(dim=(1,2,3)) + target.sum(dim=(1,2,3)) - inter\n",
    "\n",
    "    return ((inter + eps) / (union + eps)).mean().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87500cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(pred, target, eps=1e-6):\n",
    "    pred = pred.view(-1)\n",
    "    target = target.view(-1)\n",
    "    inter = (pred * target).sum()\n",
    "    return 1 - (2*inter + eps) / (pred.sum() + target.sum() + eps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40029969",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HCDataset(\"training_set\", \"training_set_pixel_size_and_HC.csv\", train_tfms)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "ds_train, ds_val = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "dl_train = DataLoader(ds_train, batch_size=4, shuffle=True)\n",
    "dl_val   = DataLoader(ds_val, batch_size=4, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0837d9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SwinSeg().to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fc8ef60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss 0.9851\n",
      "Epoch 02 | Train Loss 0.9850\n",
      "Epoch 03 | Train Loss 0.9848\n",
      "Epoch 04 | Train Loss 0.9847\n",
      "Epoch 05 | Train Loss 0.9847\n",
      "Epoch 06 | Train Loss 0.9845\n",
      "Epoch 07 | Train Loss 0.9845\n",
      "Epoch 08 | Train Loss 0.9846\n",
      "Epoch 09 | Train Loss 0.9845\n",
      "Epoch 10 | Train Loss 0.9846\n",
      "Epoch 11 | Train Loss 0.9845\n",
      "Epoch 12 | Train Loss 0.9845\n",
      "Epoch 13 | Train Loss 0.9845\n",
      "Epoch 14 | Train Loss 0.9845\n",
      "Epoch 15 | Train Loss 0.9846\n",
      "Epoch 16 | Train Loss 0.9846\n",
      "Epoch 17 | Train Loss 0.9845\n",
      "Epoch 18 | Train Loss 0.9845\n",
      "Epoch 19 | Train Loss 0.9844\n",
      "Epoch 20 | Train Loss 0.9844\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    total = 0\n",
    "\n",
    "    for img, mask, _, _ in dl_train:\n",
    "        img = img.to(device)\n",
    "        mask = mask.unsqueeze(1).to(device)\n",
    "\n",
    "        pred = model(img)\n",
    "        loss = dice_loss(pred, mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1:02d} | Train Loss {total/len(dl_train):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b9eb836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_mask(mask):\n",
    "    mask = (mask > 0.5).astype(np.uint8)\n",
    "\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask)\n",
    "    largest = 1 + np.argmax(stats[1:, cv2.CC_STAT_AREA])\n",
    "    mask = (labels == largest).astype(np.uint8)\n",
    "\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, np.ones((5,5),np.uint8))\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59fa071b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ellipse_from_mask(mask):\n",
    "    cnts,_ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    if len(cnts)==0 or len(cnts[0])<5:\n",
    "        return None\n",
    "    (cx,cy),(MA,ma),angle = cv2.fitEllipse(max(cnts, key=cv2.contourArea))\n",
    "    return cx, cy, MA/2, ma/2, angle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71672041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ellipse_circumference(a,b):\n",
    "    return math.pi*(3*(a+b)-math.sqrt((3*a+b)*(a+3*b)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "050d623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_biometry(mask, spacing):\n",
    "    ell = fit_ellipse_from_mask(mask)\n",
    "    if ell is None:\n",
    "        return None,None,None\n",
    "\n",
    "    _,_,a,b,_ = ell\n",
    "    a_mm = a * spacing\n",
    "    b_mm = b * spacing\n",
    "\n",
    "    HC  = ellipse_circumference(a_mm, b_mm)\n",
    "    BPD = 2 * b_mm\n",
    "    OFD = 2 * a_mm\n",
    "    return HC, BPD, OFD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b810096",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"training_set_pixel_size_and_HC.csv\")\n",
    "gt_hc_dict = dict(zip(df[\"filename\"], df[\"head circumference (mm)\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19ecb7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice : 0.0152\n",
      "Validation IoU  : 0.0076\n",
      "Valid HC samples: 162 / 162\n",
      "HC MAE  (mm)    : 158.67\n",
      "HC RMSE (mm)    : 169.50\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "dice_vals = []\n",
    "iou_vals  = []\n",
    "pred_hc   = []\n",
    "gt_hc     = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img, gt_mask, spacing, fname in dl_val:\n",
    "        img = img.to(device)\n",
    "        gt_mask = gt_mask.unsqueeze(1).to(device)\n",
    "\n",
    "        # ---- prediction ----\n",
    "        pred = model(img)\n",
    "\n",
    "        # ---- Dice / IoU (CORRECT) ----\n",
    "        dice_vals.append(dice_score_torch(pred, gt_mask))\n",
    "        iou_vals.append(iou_score_torch(pred, gt_mask))\n",
    "\n",
    "        # ---- HC computation (per image) ----\n",
    "        for b in range(img.size(0)):\n",
    "            pred_np = pred[b,0].cpu().numpy()\n",
    "            clean = clean_mask(pred_np)\n",
    "\n",
    "            ellipse = fit_ellipse_from_mask(clean)\n",
    "            if ellipse is None:\n",
    "                continue\n",
    "\n",
    "            _, _, a, b_ax, _ = ellipse\n",
    "            hc_pred = ellipse_circumference(\n",
    "                a * spacing[b].item(),\n",
    "                b_ax * spacing[b].item()\n",
    "            )\n",
    "\n",
    "            hc_gt = gt_hc_dict[fname[b]]\n",
    "            pred_hc.append(hc_pred)\n",
    "            gt_hc.append(hc_gt)\n",
    "\n",
    "dice_mean = np.mean(dice_vals)\n",
    "iou_mean  = np.mean(iou_vals)\n",
    "\n",
    "pred_hc = np.array(pred_hc)\n",
    "gt_hc   = np.array(gt_hc)\n",
    "\n",
    "hc_mae  = np.mean(np.abs(pred_hc - gt_hc))\n",
    "hc_rmse = np.sqrt(np.mean((pred_hc - gt_hc)**2))\n",
    "\n",
    "print(f\"Validation Dice : {dice_mean:.4f}\")\n",
    "print(f\"Validation IoU  : {iou_mean:.4f}\")\n",
    "print(f\"Valid HC samples: {len(pred_hc)} / {len(ds_val)}\")\n",
    "print(f\"HC MAE  (mm)    : {hc_mae:.2f}\")\n",
    "print(f\"HC RMSE (mm)    : {hc_rmse:.2f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
